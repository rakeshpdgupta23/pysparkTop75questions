"""Write pyspark code to split the words

Input-

inputdata=[(1,"a,b,c"),(2,"x,y,z")]

Output-

| id|new_val|
+---+-------+
|  1|      a|
|  1|      b|
|  1|      c|
|  2|      x|
|  2|      y|
|  2|      z|
+---+-------+

"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import col,split,explode
from pyspark.sql.types import StructType,StructField,StringType,IntegerType

sc=SparkSession.builder.master("local").appName("myTest").getOrCreate()
Input_data =[(1,"a,b,c"),(2,"x,y,z")]
schema = StructType([
    StructField("id", IntegerType(), True),
    StructField("values", StringType(), True)])
inputdf=sc.createDataFrame(Input_data,schema)

newdf=inputdf.withColumn("new_val",explode(split(inputdf["values"],",")))

print(newdf["id","new_val"].show())




#Q2
"""Write pyspark code to calculate salary difference of employees"""
Input_emp_sal_data=[("emp1",2011,8),("emp1",2014,10),("emp1",2016,15),("emp1",2022,95),("emp2",2013,3),("emp2",2018,9),("emp2",2020,18),("emp2",2022,35)]

schema=StructType([
    StructField("name",StringType(),True),
    StructField("year",IntegerType(),True),
    StructField("sal",IntegerType(),True)])
new_emp_df=sc.createDataFrame(Input_emp_sal_data,schema)

windowsSpec=Window.partitionBy("name").orderBy("year")

new_emp_df=new_emp_df.withColumn("SalDiff",col("sal")-coalesce(lag("sal").over(windowsSpec),"sal"))

print(new_emp_df.show())
